{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params = 'Temperature'\n",
    "dataset_size = 'small'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-c5d84736ba45>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-c6201f8cef64>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-019260d1850a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data = np.array(data)\n",
    "\n",
    "x = data\n",
    "y = np.roll(x,-1,axis=0)\n",
    "\n",
    "# print(x[1])\n",
    "# print()\n",
    "# print(y[0])\n",
    "\n",
    "value = 1\n",
    "for ori in range(len(x)-1):\n",
    "    if not value:\n",
    "        break\n",
    "    # print(ori)\n",
    "    ttt = x[ori+1]\n",
    "    fff = y[ori]\n",
    "    fin = ttt==fff\n",
    "    for g in fin:\n",
    "        for h in g:\n",
    "            if h == False:\n",
    "                print('MARHA')\n",
    "                value = 0\n",
    "                break\n",
    "\n",
    "if value:\n",
    "    print('GUD')\n",
    "    \n",
    "size = len(x)\n",
    "test = 0.1\n",
    "valid = 0.1\n",
    "train = x[:-(size * (test+valid))]\n",
    "valid = x[-(size * (test+valid)): -size*test]\n",
    "test = x[-size*test:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset_size='small', params='Temperature'):\n",
    "    # preparing path\n",
    "    if dataset_size == 'small':\n",
    "        dirr = '32x32'\n",
    "    elif dataset_size == 'large':\n",
    "        dirr = '64x64'\n",
    "    else:\n",
    "        dirr = '131x151'\n",
    "    # TODO: logic for parameters of dataset\n",
    "    \n",
    "    # create name based on arguments [local path]\n",
    "    path = '../PARSED/' + dirr + '/' + params + '.pkl'\n",
    "    \n",
    "    #loading dataset\n",
    "    with open(path, 'rb') as f:\n",
    "        data = pickle.load(f, encoding='latin1')\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_dataset(data, steps=1):\n",
    "    return np.roll(data,-1*steps,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(data, valid=0.1, test=0.1):\n",
    "    x = data\n",
    "    \n",
    "    size = len(x)\n",
    "    # split\n",
    "    train_features = x[:int(-(size * (test+valid)))]\n",
    "    valid_features= x[int(-(size * (test+valid))): int(-size*test)]\n",
    "    test_features = x[int(-size*test):]\n",
    "    \n",
    "    return train_features, valid_features, test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# around 0 => -3 -- 3 (~)\n",
    "def normalize_v1(data):\n",
    "    mean_data = np.mean(data)\n",
    "    std_data = np.std(data)\n",
    "    norm_data = (data-mean_data) / std_data\n",
    "    return norm_data, mean_data, std_data\n",
    "\n",
    "def denormalize_v1(data, mean, std):\n",
    "    data *= std\n",
    "    data += mean\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# around 0 => -0.5 -- 0.5\n",
    "def normalize_v2(data):\n",
    "    minn = np.amin(data)\n",
    "    maxx = np.amax(data)\n",
    "    \n",
    "    normalized = (data - minn) / (maxx - minn)\n",
    "    normalized -= 0.5\n",
    "    return normalized, minn, maxx\n",
    "\n",
    "def denormalize_v2(data, minn, maxx):\n",
    "    diff = maxx - minn\n",
    "    \n",
    "    data += 0.5\n",
    "    denormalized = (data * diff) + minn\n",
    "    return denormalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEFAULT\n",
      "[[276.45422 276.27136 276.13416 ... 273.79114 273.47766 273.16052]\n",
      " [276.63147 276.53528 276.4923  ... 273.63245 273.39514 273.22815]\n",
      " [276.56458 276.43884 276.42126 ... 273.75012 273.67908 273.63293]\n",
      " ...\n",
      " [281.56726 283.51086 283.5614  ... 277.09338 276.93567 275.0387 ]\n",
      " [282.6969  283.96326 283.31458 ... 276.64856 275.33777 273.17468]\n",
      " [283.42688 283.95837 283.64612 ... 275.30994 273.61536 272.9718 ]]\n",
      "NORMALIZED\n",
      "[[-0.01992336 -0.02280152 -0.02496111 ... -0.06183913 -0.06677312\n",
      "  -0.07176474]\n",
      " [-0.01713359 -0.01864761 -0.01932392 ... -0.06433687 -0.06807193\n",
      "  -0.07070032]\n",
      " [-0.01818648 -0.02016544 -0.02044213 ... -0.06248471 -0.06360292\n",
      "  -0.06432918]\n",
      " ...\n",
      " [ 0.06055355  0.09114498  0.0919404  ... -0.00986329 -0.01234564\n",
      "  -0.04220313]\n",
      " [ 0.07833356  0.09826541  0.08805549 ... -0.0168646  -0.03749585\n",
      "  -0.07154188]\n",
      " [ 0.08982307  0.09818858  0.09327382 ... -0.03793392 -0.06460586\n",
      "  -0.07473511]]\n",
      "0.5 -0.5\n",
      "DENORMALIZED\n",
      "[[276.45422 276.27136 276.13416 ... 273.79114 273.47766 273.16052]\n",
      " [276.63147 276.53528 276.4923  ... 273.63245 273.39514 273.22815]\n",
      " [276.56458 276.43884 276.42126 ... 273.75012 273.67908 273.63293]\n",
      " ...\n",
      " [281.56726 283.51086 283.5614  ... 277.09338 276.93567 275.0387 ]\n",
      " [282.6969  283.96326 283.31458 ... 276.64856 275.33777 273.17468]\n",
      " [283.42688 283.95837 283.64612 ... 275.30994 273.61536 272.9718 ]]\n"
     ]
    }
   ],
   "source": [
    "dat_x = create_dataset()\n",
    "print('DEFAULT')\n",
    "print(dat_x[0])\n",
    "\n",
    "normal, minn, maxx = normalize_v2(dat_x)\n",
    "print('NORMALIZED')\n",
    "print(normal[0])\n",
    "print(np.amax(normal), np.amin(normal))\n",
    "\n",
    "back2future = denormalize_v2(normal, minn, maxx)\n",
    "print('DENORMALIZED')\n",
    "print(back2future[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(data_array):\n",
    "    length=data_array.shape[0] #assuming the data array to be a np arry\n",
    "    permutations=np.random.permutation(length)\n",
    "    idxs=permutations[0:batch_size]\n",
    "    batch=np.zeros([batch_size, C, img_size*channel], dtype=np.float32)\n",
    "    for i in range(len(idxs)):\n",
    "        batch[i,:]=data_array[idxs[i]].reshape(C,img_size*channel)\n",
    "    return batch / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 't_f' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-6b0e02b02dc7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mddd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt_f\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 't_f' is not defined"
     ]
    }
   ],
   "source": [
    "batch_size = 24\n",
    "img_size = 32*32\n",
    "channel = 1\n",
    "C = 1\n",
    "\n",
    "ddd = next_batch(t_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, valid, test = split_dataset(dat_x, valid=0, test=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7906"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "878"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8784"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dat_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8784"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7906 + 878"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_temp_32.pkl','wb') as f:\n",
    "    pickle.dump(data_train, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_temp_32.pkl','wb') as f:\n",
    "    pickle.dump(test, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
